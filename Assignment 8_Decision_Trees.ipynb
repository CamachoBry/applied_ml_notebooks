{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be using the wine quality data set for these exercises. This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-10T00:04:57.164238Z",
     "start_time": "2017-04-09T20:04:57.158472-04:00"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Import the data and examine the features.\n",
    "* We will be using all of them to predict `color` (white or red), but the colors feature will need to be integer encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.70         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  color  \n",
       "0         9.4        5    red  \n",
       "1         9.8        5    red  \n",
       "2         9.8        5    red  \n",
       "3         9.8        6    red  \n",
       "4         9.4        5    red  \n",
       "...       ...      ...    ...  \n",
       "6492     11.2        6  white  \n",
       "6493      9.6        5  white  \n",
       "6494      9.4        6  white  \n",
       "6495     12.8        7  white  \n",
       "6496     11.8        6  white  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use `StratifiedShuffleSplit` to split data into train and test sets that are stratified by wine quality. If possible, preserve the indices of the split for question 5 below.\n",
    "* Check the percent composition of each quality level for both the train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-train composition\n",
      "0    0.753866\n",
      "1    0.246134\n",
      "Name: color, dtype: float64\n",
      "Y-test composition\n",
      "0    0.754\n",
      "1    0.246\n",
      "Name: color, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=1000, random_state=42)\n",
    "\n",
    "#Split the data from features and target\n",
    "X = data.drop('color', axis=1)\n",
    "y = data.color\n",
    "\n",
    "#Turning color into integers\n",
    "y = y.replace('white', 0).replace('red',1).astype(int)\n",
    "\n",
    "#Get data with training-test index\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "\n",
    "#Percent compostion of quality column\n",
    "print('Y-train composition')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('Y-test composition')\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "* Fit a decision tree classifier with no set limits on maximum depth, features, or leaves.\n",
    "* Determine how many nodes are present and what the depth of this (very large) tree is.\n",
    "* Using this tree, measure the prediction error in the train and test data sets. What do you think is going on here based on the differences in prediction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of nodes: 86\n",
      "Depth of tree: 22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Creating and fitting the tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "#Determining how many nodes and its depth\n",
    "print(f'Amount of nodes: {dt.get_n_leaves()}')\n",
    "print(f'Depth of tree: {dt.get_depth()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Measure error function\n",
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy': accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred)}, name=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.963710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.967611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.999818  0.984000\n",
       "precision  0.999261  0.963710\n",
       "recall     1.000000  0.971545\n",
       "f1         0.999631  0.967611"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions on training and testing data\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "train_test_error = pd.concat([measure_error(y_train, y_train_pred, 'train'), \n",
    "                              measure_error(y_test, y_test_pred, 'test')], axis=1)\n",
    "train_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "* Using grid search with cross validation, find a decision tree that performs well on the test data set. Use a different variable name for this decision tree model than in question 3 so that both can be used in question 6.\n",
    "* Determine the number of nodes and the depth of this tree.\n",
    "* Measure the errors on the training and test sets as before and compare them to those from the tree in question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of nodes: 50\n",
      "Depth of tree: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Parameters to optimized via GridSearch\n",
    "parameters = {'max_depth': range(1, dt.tree_.max_depth+1, 2),\n",
    "             'max_features': range(1, dt.max_features_)}\n",
    "\n",
    "#Gridsearch instance\n",
    "dt2 = DecisionTreeClassifier(random_state=42)\n",
    "dt_gs = GridSearchCV(dt2, parameters, cv=5)\n",
    "\n",
    "#Fitting the model\n",
    "dt_gs.fit(X_train, y_train)\n",
    "\n",
    "#Number of nodes and depth\n",
    "print(f'Amount of nodes: {dt_gs.best_estimator_.get_n_leaves()}')\n",
    "print(f'Depth of tree: {dt_gs.best_estimator_.get_depth()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.983539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.984479</td>\n",
       "      <td>0.971545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.991440</td>\n",
       "      <td>0.977505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              train      test\n",
       "accuracy   0.995816  0.989000\n",
       "precision  0.998501  0.983539\n",
       "recall     0.984479  0.971545\n",
       "f1         0.991440  0.977505"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions on training and testing data\n",
    "y_train_pred2 = dt_gs.predict(X_train)\n",
    "y_test_pred2 = dt_gs.predict(X_test)\n",
    "\n",
    "train_test_error = pd.concat([measure_error(y_train, y_train_pred2, 'train'), \n",
    "                              measure_error(y_test, y_test_pred2, 'test')], axis=1)\n",
    "train_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "* Re-split the data into `X` and `y` parts, this time with `residual_sugar` being the predicted (`y`) data. *Note:* if the indices were preserved from the `StratifiedShuffleSplit` output in question 2, they can be used again to split the data.\n",
    "* Using grid search with cross validation, find a decision tree **regression** model that performs well on the test data set.\n",
    "* Measure the errors on the training and test sets using mean squared error.\n",
    "* Make a plot of actual *vs* predicted residual sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn\n",
    "\n",
    "#Splitting data\n",
    "X = data.drop('residual_sugar', axis=1)\n",
    "X['color'] = X['color'].replace('white', 0).replace('red',1).astype(int)\n",
    "y = data.residual_sugar\n",
    "\n",
    "#Creating training and test data split\n",
    "X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "    \n",
    "#Tree regression instance\n",
    "dt_reg = DecisionTreeRegressor(random_state=42)\n",
    "dt_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=42,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': range(1, 33, 2),\n",
       "                         'max_features': range(1, 12)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "parameters = {'max_depth': range(1, dt_reg.tree_.max_depth+1, 2), 'max_features': range(1, dt_reg.max_features_)}\n",
    "\n",
    "#GridSearch instance\n",
    "dtr_gs = GridSearchCV(dt_reg, parameters, cv=5)\n",
    "dtr_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_mse</th>\n",
       "      <td>0.001805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mse</th>\n",
       "      <td>2.643804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE\n",
       "train_mse  0.001805\n",
       "test_mse   2.643804"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions\n",
    "y_train_pred_dtr = dtr_gs.predict(X_train)\n",
    "y_test_pred_dtr = dtr_gs.predict(X_test)\n",
    "\n",
    "#Errors\n",
    "train_test_mse = pd.Series({'train_mse': mean_squared_error(y_train, y_train_pred_dtr),\n",
    "                      'test_mse': mean_squared_error(y_test, y_test_pred_dtr)}, name='MSE').to_frame()\n",
    "\n",
    "\n",
    "\n",
    "train_test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13345a510>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = plt.axes()\n",
    "\n",
    "ph_test_prediction = pd.DataFrame({'actual': y_test, 'predicted': y_test_pred_dtr}).set_index('actual').sort_index()\n",
    "\n",
    "ph_test_prediction.plot(marker='o', ls='', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 *(Optional)*\n",
    "\n",
    "This question is optional as it requires an additional command line program (GraphViz) and Python library (PyDotPlus). GraphViz can be installed with a package manager on Linux and Mac. For PyDotPlus, either `pip` or `conda` (`conda install -c conda-forge pydotplus`) can be used to install the library.\n",
    "\n",
    "Once these programs are installed:\n",
    "\n",
    "* Create a visualization of the decision tree from question 3, where wine color was predicted and the number of features and/or splits are not limited.\n",
    "* Create a visualization of the decision tree from question 4, where wine color was predicted but a grid search was used to find the optimal depth and number of features.\n",
    "\n",
    "The decision tree from question 5 will likely have too many nodes to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tree in module sklearn.tree._tree:\n",
      "\n",
      "class Tree(builtins.object)\n",
      " |  Array-based representation of a binary decision tree.\n",
      " |  \n",
      " |  The binary tree is represented as a number of parallel arrays. The i-th\n",
      " |  element of each array holds information about the node `i`. Node 0 is the\n",
      " |  tree's root. You can find a detailed description of all arrays in\n",
      " |  `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      " |  nodes, resp. In this case the values of nodes of the other type are\n",
      " |  arbitrary!\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  node_count : int\n",
      " |      The number of nodes (internal nodes + leaves) in the tree.\n",
      " |  \n",
      " |  capacity : int\n",
      " |      The current capacity (i.e., size) of the arrays, which is at least as\n",
      " |      great as `node_count`.\n",
      " |  \n",
      " |  max_depth : int\n",
      " |      The depth of the tree, i.e. the maximum depth of its leaves.\n",
      " |  \n",
      " |  children_left : array of int, shape [node_count]\n",
      " |      children_left[i] holds the node id of the left child of node i.\n",
      " |      For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      " |      children_left[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] <= threshold[i].\n",
      " |  \n",
      " |  children_right : array of int, shape [node_count]\n",
      " |      children_right[i] holds the node id of the right child of node i.\n",
      " |      For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      " |      children_right[i] > i. This child handles the case where\n",
      " |      X[:, feature[i]] > threshold[i].\n",
      " |  \n",
      " |  feature : array of int, shape [node_count]\n",
      " |      feature[i] holds the feature to split on, for the internal node i.\n",
      " |  \n",
      " |  threshold : array of double, shape [node_count]\n",
      " |      threshold[i] holds the threshold for the internal node i.\n",
      " |  \n",
      " |  value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      " |      Contains the constant prediction value of each node.\n",
      " |  \n",
      " |  impurity : array of double, shape [node_count]\n",
      " |      impurity[i] holds the impurity (i.e., the value of the splitting\n",
      " |      criterion) at node i.\n",
      " |  \n",
      " |  n_node_samples : array of int, shape [node_count]\n",
      " |      n_node_samples[i] holds the number of training samples reaching node i.\n",
      " |  \n",
      " |  weighted_n_node_samples : array of int, shape [node_count]\n",
      " |      weighted_n_node_samples[i] holds the weighted number of training samples\n",
      " |      reaching node i.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |      Getstate re-implementation, for pickling.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Reduce re-implementation, for pickling.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |      Setstate re-implementation, for unpickling.\n",
      " |  \n",
      " |  apply(...)\n",
      " |      Finds the terminal region (=leaf node) for each sample in X.\n",
      " |  \n",
      " |  compute_feature_importances(...)\n",
      " |      Computes the importance of each feature (aka variable).\n",
      " |  \n",
      " |  compute_partial_dependence(...)\n",
      " |      Partial dependence of the response on the ``target_feature`` set.\n",
      " |      \n",
      " |      For each sample in ``X`` a tree traversal is performed.\n",
      " |      Each traversal starts from the root with weight 1.0.\n",
      " |      \n",
      " |      At each non-leaf node that splits on a target feature, either\n",
      " |      the left child or the right child is visited based on the feature\n",
      " |      value of the current sample, and the weight is not modified.\n",
      " |      At each non-leaf node that splits on a complementary feature,\n",
      " |      both children are visited and the weight is multiplied by the fraction\n",
      " |      of training samples which went to each child.\n",
      " |      \n",
      " |      At each leaf, the value of the node is multiplied by the current\n",
      " |      weight (weights sum to 1 for all visited terminal nodes).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : view on 2d ndarray, shape (n_samples, n_target_features)\n",
      " |          The grid points on which the partial dependence should be\n",
      " |          evaluated.\n",
      " |      target_feature : view on 1d ndarray, shape (n_target_features)\n",
      " |          The set of target features for which the partial dependence\n",
      " |          should be evaluated.\n",
      " |      out : view on 1d ndarray, shape (n_samples)\n",
      " |          The value of the partial dependence function on each grid\n",
      " |          point.\n",
      " |  \n",
      " |  decision_path(...)\n",
      " |      Finds the decision path (=node) for each sample in X.\n",
      " |  \n",
      " |  predict(...)\n",
      " |      Predict target for X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  capacity\n",
      " |  \n",
      " |  children_left\n",
      " |  \n",
      " |  children_right\n",
      " |  \n",
      " |  feature\n",
      " |  \n",
      " |  impurity\n",
      " |  \n",
      " |  max_depth\n",
      " |  \n",
      " |  max_n_classes\n",
      " |  \n",
      " |  n_classes\n",
      " |  \n",
      " |  n_features\n",
      " |  \n",
      " |  n_leaves\n",
      " |  \n",
      " |  n_node_samples\n",
      " |  \n",
      " |  n_outputs\n",
      " |  \n",
      " |  node_count\n",
      " |  \n",
      " |  threshold\n",
      " |  \n",
      " |  value\n",
      " |  \n",
      " |  weighted_n_node_samples\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn.tree._tree.Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1234, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
